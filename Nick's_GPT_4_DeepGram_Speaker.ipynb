{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LexMed-AI/st_deepgram_playground/blob/main/Nick's_GPT_4_DeepGram_Speaker.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qobp_jlRo4QW"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkT8o2QroyB0",
        "outputId": "a547ec39-a84c-4d7b-9255-e10725dc6894"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: ffmpeg-python in /usr/local/lib/python3.10/dist-packages (0.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.2.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from ffmpeg-python) (0.18.3)\n",
            "Requirement already satisfied: deepgram-sdk==2.12.0 in /usr/local/lib/python3.10/dist-packages (2.12.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from deepgram-sdk==2.12.0) (3.9.5)\n",
            "Requirement already satisfied: websockets in /usr/local/lib/python3.10/dist-packages (from deepgram-sdk==2.12.0) (12.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->deepgram-sdk==2.12.0) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->deepgram-sdk==2.12.0) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->deepgram-sdk==2.12.0) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->deepgram-sdk==2.12.0) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->deepgram-sdk==2.12.0) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->deepgram-sdk==2.12.0) (4.0.3)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.0->aiohttp->deepgram-sdk==2.12.0) (3.7)\n",
            "Requirement already satisfied: asyncio in /usr/local/lib/python3.10/dist-packages (3.4.3)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement time (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for time\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.23.6)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.1)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.10/dist-packages (1.6.0)\n"
          ]
        }
      ],
      "source": [
        "! pip install requests ffmpeg-python\n",
        "! pip install deepgram-sdk==2.12.0\n",
        "! pip install asyncio\n",
        "! pip install time\n",
        "! pip install openai\n",
        "!pip install nest_asyncio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cFhA5hioe-f_"
      },
      "outputs": [],
      "source": [
        "from deepgram import Deepgram\n",
        "import asyncio, json, os\n",
        "from google.colab import userdata\n",
        "\n",
        "dg_key = userdata.get('dg_key')\n",
        "dg = Deepgram(dg_key)\n",
        "\n",
        "'''\n",
        "The most common audio formats and encodings we support\n",
        "include mp3, mp4, mp2, aac, wav, flac, pcm, m4a, ogg, opus, and webm,\n",
        "So feel free to adjust the `MIMETYPE` variable as needed\n",
        "'''\n",
        "MIMETYPE = 'ogg'\n",
        "\n",
        "#Note: You can use '.' if your audio is in the root\n",
        "DIRECTORY = '.'\n",
        "\n",
        "\n",
        "# Feel free to modify your model's parameters as you wish!\n",
        "options = {\n",
        "    \"smart_format\": True,\n",
        "    \"diarize\": True,\n",
        "    \"model\": 'enhanced',\n",
        "}\n",
        "\n",
        "#This function is what calls on the model to transcribe\n",
        "def main():\n",
        "    audio_folder = os.listdir(DIRECTORY)\n",
        "    for audio_file in audio_folder:\n",
        "        if audio_file.endswith(MIMETYPE):\n",
        "          with open(f\"{DIRECTORY}/{audio_file}\", \"rb\") as f:\n",
        "              source = {\"buffer\": f, \"mimetype\":'audio/'+MIMETYPE}\n",
        "              res = dg.transcription.sync_prerecorded(source, options)\n",
        "              with open(f\"./{audio_file[:-4]}.json\", \"w\") as transcript:\n",
        "                  json.dump(res, transcript, indent=4)\n",
        "    return\n",
        "\n",
        "main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmiUEqUCw-Q6",
        "outputId": "fe1abee0-70ad-4e11-9ec9-23ff9e824acf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Transcript written to Parsed_JSON.json\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "DIRECTORY = '/content/'  # Define the directory to scan for JSON files\n",
        "\n",
        "def format_transcript_data(raw_transcript):\n",
        "    transcript_data = []\n",
        "    items = raw_transcript.get('results', {}).get('channels', [{}])[0].get('alternatives', [{}])[0]\n",
        "    paragraphs = items.get('paragraphs', {}).get('paragraphs', [])\n",
        "\n",
        "    if not paragraphs:\n",
        "        print(\"No paragraphs found in transcript.\")\n",
        "        return []\n",
        "\n",
        "    try:\n",
        "        last_speaker_id = None\n",
        "        id_counter = 0\n",
        "\n",
        "        for paragraph in paragraphs:\n",
        "            speaker_id = str(paragraph['speaker'])\n",
        "            transcript_text = ' '.join(sentence['text'] for sentence in paragraph.get('sentences', []))\n",
        "            start_time = paragraph.get('sentences', [{}])[0].get('start', 0)\n",
        "\n",
        "            # Determine if the current speaker is the same as the last one and spoken consecutively\n",
        "            if speaker_id != last_speaker_id:\n",
        "                id_counter += 1  # Increment ID since a new speaker or non-consecutive speech has started\n",
        "                last_speaker_id = speaker_id\n",
        "\n",
        "            # Check if an entry for the current ID already exists\n",
        "            if id_counter not in [entry['id'] for entry in transcript_data]:\n",
        "                # Create a new entry for this ID\n",
        "                transcript_object = {\n",
        "                    'id': id_counter,\n",
        "                    'ts': start_time,\n",
        "                    'speaker': \"\",\n",
        "                    'text': transcript_text\n",
        "                }\n",
        "                transcript_data.append(transcript_object)\n",
        "            else:\n",
        "                # Append text to the existing entry for this ID\n",
        "                for entry in transcript_data:\n",
        "                    if entry['id'] == id_counter:\n",
        "                        entry['text'] += \" \" + transcript_text\n",
        "                        break\n",
        "\n",
        "        return transcript_data\n",
        "    except Exception as error:\n",
        "        print(f\"Error processing the transcript data: {error}\")\n",
        "        return []\n",
        "\n",
        "def create_transcript(input_filename):\n",
        "    with open(input_filename, \"r\") as file:\n",
        "        raw_transcript = json.load(file)\n",
        "        formatted_data = format_transcript_data(raw_transcript)\n",
        "        output_filename = \"Parsed_JSON.json\"  # Set the desired output file name\n",
        "        with open(output_filename, \"w\") as outfile:\n",
        "            json.dump(formatted_data, outfile, indent=4)\n",
        "\n",
        "def print_transcript():\n",
        "    for filename in os.listdir(DIRECTORY):\n",
        "        if filename.endswith('.json'):\n",
        "            create_transcript(filename)\n",
        "            print(f\"Transcript written to Parsed_JSON.json\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    print_transcript()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ca11wZVO3l92"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import math\n",
        "import os\n",
        "import logging\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "def count_tokens(text):\n",
        "    return len(text.split())\n",
        "\n",
        "def chunk_transcript(parsed_json_file, output_directory, max_tokens=700, overlap_tokens=200):\n",
        "    try:\n",
        "        with open(parsed_json_file, 'r') as file:\n",
        "            transcript_data = json.load(file)\n",
        "\n",
        "        if not transcript_data:\n",
        "            logger.warning(\"No data found in the file.\")\n",
        "            return\n",
        "\n",
        "        logger.info(f\"Total entries in data: {len(transcript_data)}\")\n",
        "\n",
        "        chunks = []\n",
        "        current_chunk = []\n",
        "        current_token_count = 0\n",
        "        overlap_entries = []\n",
        "\n",
        "        for entry in transcript_data:\n",
        "            entry_text = entry['text']\n",
        "            entry_token_count = count_tokens(entry_text)\n",
        "\n",
        "            if current_token_count + entry_token_count <= max_tokens:\n",
        "                current_chunk.append(entry)\n",
        "                current_token_count += entry_token_count\n",
        "            else:\n",
        "                chunks.append(current_chunk)\n",
        "                overlap_token_count = sum(count_tokens(e['text']) for e in overlap_entries)\n",
        "                current_chunk = overlap_entries + [entry]\n",
        "                current_token_count = overlap_token_count + entry_token_count\n",
        "                overlap_entries = []\n",
        "\n",
        "            if current_token_count >= max_tokens - overlap_tokens:\n",
        "                overlap_entries = current_chunk[-2:]\n",
        "\n",
        "        if current_chunk:\n",
        "            chunks.append(current_chunk)\n",
        "\n",
        "        num_chunks = len(chunks)\n",
        "        logger.info(f\"Total chunks created: {num_chunks}\")\n",
        "\n",
        "        num_digits = int(math.log10(num_chunks)) + 1 if num_chunks > 0 else 1\n",
        "\n",
        "        for i, chunk in enumerate(chunks, start=1):\n",
        "            chunk_filename = f\"Parsed_JSON_Chunk_{i:0{num_digits}d}.json\"\n",
        "            chunk_filepath = os.path.join(output_directory, chunk_filename)\n",
        "            with open(chunk_filepath, 'w') as file:\n",
        "                json.dump(chunk, file, indent=4)\n",
        "            logger.info(f\"Chunk saved to {chunk_filepath}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error occurred during chunking: {str(e)}\")\n",
        "\n",
        "# Specify the output directory where the chunked files should be saved\n",
        "output_directory = '/content/chunked_files/'\n",
        "\n",
        "# Create the output directory if it doesn't exist\n",
        "os.makedirs(output_directory, exist_ok=True)\n",
        "\n",
        "# Usage\n",
        "parsed_json_file = 'Parsed_JSON.json'\n",
        "chunk_transcript(parsed_json_file, output_directory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hrRZjE746Rbs"
      },
      "outputs": [],
      "source": [
        "system_prompt = json.dumps({\n",
        "    \"role\": \"Improve speaker diarization and formatting for ASR-generated Social Security Disability hearing transcripts.\",\n",
        "    \"input\": {\n",
        "        \"format\": \"JSON array\",\n",
        "        \"fields\": [\"id\", \"ts\", \"speaker\", \"text\"]\n",
        "    },\n",
        "    \"tasks\": [\n",
        "        \"Rectify spelling, titles, and terminology in the context of a Social Securirty Disability hearing\",\n",
        "        \"Determine speakers labels using contextual information from dialog\"\n",
        "    ],\n",
        "    \"format\": {\n",
        "        \"timestamps\": \"Format: [hh:mm:ss]\",\n",
        "        \"correct_speaker_labels\": {\n",
        "            \"Administrative Law Judge\": \"ALJ\",\n",
        "            \"Claimant\": \"Clmt\",\n",
        "            \"Attorney\": \"Atty\",\n",
        "            \"Vocational Expert\": \"VE\",\n",
        "            \"Medical Expert\": \"ME\",\n",
        "            \"Hearing Reporter\": \"HR\",\n",
        "            \"Witnesses\": [\"W1\", \"W2\", \"W3\"],\n",
        "        }\n",
        "    },\n",
        "    \"corrections\": {\n",
        "        \"spelling_punctuation\": \"Rectify mistakes, assure proper capitalization and punctuation.\",\n",
        "        \"context\": \"Use context to rectify inaccuracies, align with hearing subjects.\",\n",
        "        \"jargon\": \"Rectify inaccurate legal, medical, and occupational terms based on the context of SSA disability hearing.\"\n",
        "    },\n",
        "    \"standardize\": {\n",
        "        \"ssn\": \"Format: ###-##-####\",\n",
        "        \"dot\": \"Format: ###.###-###\",\n",
        "        \"dates\": \"Format: mm/dd/yyyy\",\n",
        "        \"timestamp\": \"Format: hh:mm:ss\",\n",
        "        \"titles\": \"Standardize: Ms., Mr., Dr., etc.\"\n",
        "    },\n",
        "    \"guidelines\": {\n",
        "        \"anonymity\": \"Keep LLM status anonymous and avoid disclaimers regarding ethics or confidentiality.\",\n",
        "        \"integrity\": \"Stick to federal court standards.\",\n",
        "        \"accuracy\": \"No placeholders or additional dialogue.\",\n",
        "        \"output\": \"Return ONLY a JSON array of objects with 'id', 'ts', 'speaker', and 'text' fields, like this: [{\\\"id\\\": 0, \\\"ts\\\": \\\"...\\\", \\\"speaker\\\": \\\"...\\\", \\\"text\\\": \\\"...\\\"}, ...]\"\n",
        "    }\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n1EmCtNA7Qg3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import logging\n",
        "import openai\n",
        "import asyncio\n",
        "import aiohttp\n",
        "import time\n",
        "from google.colab import userdata\n",
        "from tqdm import tqdm\n",
        "import nest_asyncio\n",
        "\n",
        "nest_asyncio.apply()\n",
        "\n",
        "\n",
        "# Initialize logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "# Retrieve the API key from Colab's secret manager\n",
        "api_key = userdata.get('openai_api_key')\n",
        "if not api_key:\n",
        "    logging.error(\"API key not found. Please ensure it's set in Colab's secret manager.\")\n",
        "    raise ValueError(\"API key not found\")\n",
        "\n",
        "# Initialize OpenAI GPT-4 client\n",
        "openai.api_key = api_key\n",
        "\n",
        "async def send_to_gpt4(system_prompt, chunk_data, model=\"gpt-4-turbo-2024-04-09\"):\n",
        "    \"\"\"Send structured system description to GPT-4 and return the response.\"\"\"\n",
        "    try:\n",
        "        response = await asyncio.to_thread(openai.chat.completions.create,\n",
        "            model=model,\n",
        "            messages=[\n",
        "                {\n",
        "                    \"role\": \"system\",\n",
        "                    \"content\": \"You are an excellent optomizer of raw ARS transcripts.  Your output is limited to JSON.\"\n",
        "                },\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": system_prompt\n",
        "                },\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": json.dumps(chunk_data)\n",
        "                }\n",
        "            ]\n",
        "        )\n",
        "        if response.choices:\n",
        "            return response.choices[0].message.content\n",
        "        else:\n",
        "            logging.info(\"No content returned in the response.\")\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error sending data to GPT-4: {e}\")\n",
        "        return None\n",
        "\n",
        "DIRECTORY = '/content/'\n",
        "\n",
        "async def fetch_response(session, chunk_file):\n",
        "    try:\n",
        "        with open(chunk_file, 'r') as file:\n",
        "            chunk_data = json.load(file)\n",
        "        response = await send_to_gpt4(system_prompt, chunk_data)\n",
        "        return response\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error processing chunk file {chunk_file}: {e}\")\n",
        "        return None\n",
        "\n",
        "async def process_chunks_and_aggregate(chunked_files_directory, output_file=\"finalized_transcript.json\"):\n",
        "    chunked_files = sorted([os.path.join(chunked_files_directory, file) for file in os.listdir(chunked_files_directory) if file.endswith('.json')])\n",
        "    responses = []\n",
        "\n",
        "    async with aiohttp.ClientSession() as session:\n",
        "        tasks = []\n",
        "        for chunk_file in tqdm(chunked_files, desc=\"Processing chunks\"):\n",
        "            task = asyncio.ensure_future(fetch_response(session, chunk_file))\n",
        "            tasks.append(task)\n",
        "            responses = await asyncio.gather(*tasks, return_exceptions=True)\n",
        "\n",
        "    aggregated_json = []\n",
        "    for response in tqdm(responses, desc=\"Aggregating responses\"):\n",
        "        if response:\n",
        "            try:\n",
        "                chunk_data = json.loads(response)\n",
        "                aggregated_json.extend(chunk_data)\n",
        "            except Exception as e:\n",
        "                logging.error(f\"Error parsing response: {e}\")\n",
        "\n",
        "    # Sort the aggregated JSON based on the 'id' field\n",
        "    aggregated_json = sorted(aggregated_json, key=lambda x: x['id'])\n",
        "\n",
        "    # Write the aggregated JSON to the output file\n",
        "    with open(output_file, 'w') as file:\n",
        "        json.dump(aggregated_json, file, indent=2)\n",
        "\n",
        "    return aggregated_json\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    start_time = time.time()\n",
        "    chunked_files_directory = '/content/chunked_files'  # Specify the directory containing the chunked files\n",
        "    aggregated_json = asyncio.get_event_loop().run_until_complete(process_chunks_and_aggregate(chunked_files_directory))\n",
        "    execution_time = time.time() - start_time\n",
        "    print(f\"Execution time: {execution_time} seconds\")\n",
        "    print(\"\\nAggregated JSON:\")\n",
        "    print(json.dumps(aggregated_json, indent=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQhIumTxCMQm",
        "outputId": "ffcc22ea-d4b6-4ace-c6ba-eb3621c05163"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Formatted transcript saved to formatted_transcript.txt\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "def format_transcript(input_file=\"finalized_transcript.json\", output_file=\"formatted_transcript.txt\"):\n",
        "    # Read the JSON data from file\n",
        "    with open(input_file, 'r') as file:\n",
        "        aggregated_json = json.load(file)\n",
        "\n",
        "    transcript_lines = []\n",
        "    previous_entry = None  # To store the previous entry for comparison\n",
        "\n",
        "    for entry in aggregated_json:\n",
        "        if previous_entry and entry['id'] == previous_entry['id'] and entry['text'] == previous_entry['text']:\n",
        "            continue  # Skip this entry if it's a duplicate of the previous one\n",
        "\n",
        "        current_speaker = entry['speaker']\n",
        "        formatted_time = entry['ts']  # Timestamp is already in HH:MM:SS format\n",
        "\n",
        "        # Check for speaker changes to add additional spacing\n",
        "        if previous_entry and current_speaker != previous_entry['speaker']:\n",
        "            transcript_lines.append(\"\\n\\n\")  # Add two newlines for speaker change\n",
        "        elif transcript_lines:\n",
        "            transcript_lines.append(\"\\n\")  # Add one newline for continued dialogue\n",
        "\n",
        "        # Format the line as \"(Timestamp) Speaker: Text\"\n",
        "        formatted_line = f\"({formatted_time}) {current_speaker}: {entry['text']}\"\n",
        "        transcript_lines.append(formatted_line)\n",
        "\n",
        "        previous_entry = entry  # Update the previous entry\n",
        "\n",
        "    # Write the formatted lines to the output file\n",
        "    with open(output_file, 'w') as file:\n",
        "        file.writelines(transcript_lines)\n",
        "\n",
        "    print(f\"Formatted transcript saved to {output_file}\")\n",
        "\n",
        "# Call the function to start the formatting process\n",
        "format_transcript()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN54rCDZoM6dtlaA98KA/EY",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}